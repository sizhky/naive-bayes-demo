{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step-2-coarse-tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0zZxcCIgxwnAv/QBR0/NZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sizhky/naive-bayes-demo/blob/main/spam-ham/step_2_coarse_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ciqa4--dBX"
      },
      "source": [
        "%%capture\n",
        "!pip install torch_snippets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol0YXrc1uaTl",
        "outputId": "afd89402-f626-4a43-bd2f-a322222ad8ea"
      },
      "source": [
        "## Setup and imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_snippets import unzip_file, line\n",
        "\n",
        "if not os.path.exists('SMSSpamCollection'):\n",
        "    urllib.request.urlretrieve (\"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\", \"smsspamcollection.zip\")\n",
        "    # Extracting the dataset\n",
        "    unzip_file('smsspamcollection.zip', './')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 05:05:39.217 | WARNING  | torch_snippets.torch_loader:<module>:233 - Not importing Lightning Report\n",
            "2021-07-29 05:05:39.225 | WARNING  | torch_snippets:<module>:13 - sklearn is not found. Skipping relevant imports from submodule `sklegos`\n",
            "Exception: No module named 'sklego'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlsoCf8W-6Wy"
      },
      "source": [
        "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None)\n",
        "df.columns = ['class','content']\n",
        "trn_df, val_df = train_test_split(df)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cehv7mE2msOh",
        "outputId": "9efa5899-f699-4690-be58-0c67584b9929"
      },
      "source": [
        "from sklearn.feature_extraction import text\n",
        "print([f for f in dir(text) if 'Vector' in f])\n",
        "\n",
        "from sklearn import naive_bayes\n",
        "print([f for f in dir(naive_bayes) if 'NB' in f])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CountVectorizer', 'HashingVectorizer', 'TfidfVectorizer', 'VectorizerMixin', '_VectorizerMixin']\n",
            "['BaseDiscreteNB', 'BaseNB', 'BernoulliNB', 'CategoricalNB', 'ComplementNB', 'GaussianNB', 'MultinomialNB', '_BaseDiscreteNB', '_BaseNB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXOeCna5hkxf"
      },
      "source": [
        "from sklearn.feature_extraction.text import (\n",
        "    CountVectorizer, TfidfVectorizer\n",
        ")\n",
        "from sklearn.naive_bayes import (\n",
        "    MultinomialNB,\n",
        "    BernoulliNB\n",
        ")\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# print([f for f in dir(naive_bayes) if 'NB' in f])\n",
        "\n",
        "classes = [\"HAM\", \"SPAM\"]\n",
        "def experiment(**kwargs):\n",
        "    _vectorizer = kwargs.get('vectorizer', CountVectorizer)\n",
        "    vectorizer = _vectorizer(\n",
        "        max_df=kwargs.get('max_df', 1.0),\n",
        "        min_df=kwargs.get('min_df', 1),\n",
        "        stop_words=kwargs.get('stop_words')\n",
        "    )\n",
        "    vectorizer.fit(trn_df['content'])\n",
        "    words = vectorizer.get_feature_names()\n",
        "\n",
        "    _nb_model = kwargs.get('nb', MultinomialNB)\n",
        "\n",
        "    trn = vectorizer.transform(trn_df['content']).todense()\n",
        "    val = vectorizer.transform(val_df['content']).todense()\n",
        "\n",
        "    if _nb_model == BernoulliNB:\n",
        "        trn = trn > 0\n",
        "        val = val > 0\n",
        "\n",
        "    nb = _nb_model(kwargs.get('alpha', 1.0))\n",
        "    nb.fit(trn, trn_df['class'])\n",
        "\n",
        "    _y = nb.predict(val)\n",
        "    y = val_df['class']\n",
        "\n",
        "    print(confusion_matrix(y, _y))\n",
        "    print(classification_report(y, _y))\n",
        "    \n",
        "    feature_probs = np.array(nb.feature_log_prob_)\n",
        "    k = kwargs.get('k', 15)\n",
        "    for i in range(len(feature_probs)):\n",
        "        print(f'Top {k} features for {classes[i]}')\n",
        "        _f = np.argsort(feature_probs[i])[-k:]\n",
        "        print([words[j] for j in _f])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pRjQuF2nH_x",
        "outputId": "92f7f0e7-7e36-4768-d6fa-70babd144481"
      },
      "source": [
        "experiment()\n",
        "line()\n",
        "experiment(stop_words='english')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1192    5]\n",
            " [  26  170]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99      1197\n",
            "        spam       0.97      0.87      0.92       196\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.93      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['but', 'can', 'have', 'for', 'of', 'that', 'is', 'it', 'me', 'my', 'and', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['text', 'mobile', 'is', 'on', 'ur', 'txt', 'now', 'or', 'the', 'for', 'your', 'free', 'you', 'call', 'to']\n",
            "==================================================================\n",
            "[[1191    6]\n",
            " [  23  173]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.99      0.99      1197\n",
            "        spam       0.97      0.88      0.92       196\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.97      0.94      0.96      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['need', 'love', 'time', 'day', 'come', 'like', 'know', 'good', 'ur', 'got', 'll', 'ok', 'just', 'lt', 'gt']\n",
            "Top 15 features for SPAM\n",
            "['new', 'won', 'nokia', 'cash', 'just', 'www', 'prize', 'reply', 'claim', 'stop', 'text', 'mobile', 'ur', 'txt', 'free']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COexYO9dVLa3",
        "outputId": "b3c6ad89-fd25-4316-f3e2-e5e5e33814ba"
      },
      "source": [
        "experiment()\n",
        "line()\n",
        "experiment(vectorizer=TfidfVectorizer)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1192    5]\n",
            " [  26  170]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99      1197\n",
            "        spam       0.97      0.87      0.92       196\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.93      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['but', 'can', 'have', 'for', 'of', 'that', 'is', 'it', 'me', 'my', 'and', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['text', 'mobile', 'is', 'on', 'ur', 'txt', 'now', 'or', 'the', 'for', 'your', 'free', 'you', 'call', 'to']\n",
            "==================================================================\n",
            "[[1197    0]\n",
            " [  73  123]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.94      1.00      0.97      1197\n",
            "        spam       1.00      0.63      0.77       196\n",
            "\n",
            "    accuracy                           0.95      1393\n",
            "   macro avg       0.97      0.81      0.87      1393\n",
            "weighted avg       0.95      0.95      0.94      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['have', 'not', 'are', 'can', 'ok', 'that', 'is', 'and', 'it', 'my', 'me', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['from', 'stop', 'claim', 'prize', 'text', 'now', 'for', 'mobile', 'txt', 'you', 'or', 'your', 'free', 'call', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmhALEF0nLRK",
        "outputId": "fdf503cf-4637-4e31-9020-4888fc411fd8"
      },
      "source": [
        "experiment()\n",
        "line()\n",
        "experiment(nb=BernoulliNB)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1192    5]\n",
            " [  26  170]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99      1197\n",
            "        spam       0.97      0.87      0.92       196\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.93      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['but', 'can', 'have', 'for', 'of', 'that', 'is', 'it', 'me', 'my', 'and', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['text', 'mobile', 'is', 'on', 'ur', 'txt', 'now', 'or', 'the', 'for', 'your', 'free', 'you', 'call', 'to']\n",
            "==================================================================\n",
            "[[1197    0]\n",
            " [  48  148]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1197\n",
            "        spam       1.00      0.76      0.86       196\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.98      0.88      0.92      1393\n",
            "weighted avg       0.97      0.97      0.96      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['but', 'can', 'have', 'for', 'of', 'that', 'it', 'is', 'my', 'me', 'and', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['have', 'mobile', 'on', 'from', 'is', 'txt', 'the', 'now', 'for', 'free', 'or', 'your', 'you', 'call', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu-mupeQofKu",
        "outputId": "74a6bc59-8c7d-4a43-ab3b-c3e225344bac"
      },
      "source": [
        "experiment()\n",
        "line()\n",
        "experiment(vectorizer=TfidfVectorizer, nb=BernoulliNB)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1192    5]\n",
            " [  26  170]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99      1197\n",
            "        spam       0.97      0.87      0.92       196\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.93      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['but', 'can', 'have', 'for', 'of', 'that', 'is', 'it', 'me', 'my', 'and', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['text', 'mobile', 'is', 'on', 'ur', 'txt', 'now', 'or', 'the', 'for', 'your', 'free', 'you', 'call', 'to']\n",
            "==================================================================\n",
            "[[1197    0]\n",
            " [  48  148]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1197\n",
            "        spam       1.00      0.76      0.86       196\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.98      0.88      0.92      1393\n",
            "weighted avg       0.97      0.97      0.96      1393\n",
            "\n",
            "Top 15 features for HAM\n",
            "['but', 'can', 'have', 'for', 'of', 'that', 'it', 'is', 'my', 'me', 'and', 'in', 'the', 'to', 'you']\n",
            "Top 15 features for SPAM\n",
            "['have', 'mobile', 'on', 'from', 'is', 'txt', 'the', 'now', 'for', 'free', 'or', 'your', 'you', 'call', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZLwQsoWo4O4"
      },
      "source": [
        "# best combination:\n",
        "#     CountVectorizer,\n",
        "#     MultinomialNB,\n",
        "#     stop_words='english'"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}